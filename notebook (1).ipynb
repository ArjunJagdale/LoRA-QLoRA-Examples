{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8246b47c",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">Jupyter Help</summary>\n",
    "    \n",
    "Having trouble testing your work? Double-check that you have followed the steps below to write, run, save, and test your code!\n",
    "    \n",
    "[Click here for a walkthrough GIF of the steps below](https://static-assets.codecademy.com/Courses/ds-python/jupyter-help.gif)\n",
    "\n",
    "Run all initial cells to import libraries and datasets. Then follow these steps for each question:\n",
    "    \n",
    "1. Add your solution to the cell with `## YOUR SOLUTION HERE ## `.\n",
    "2. Run the cell by selecting the `Run` button or the `Shift`+`Enter` keys.\n",
    "3. Save your work by selecting the `Save` button, the `command`+`s` keys (Mac), or `control`+`s` keys (Windows).\n",
    "4. Select the `Test Work` button at the bottom left to test your work.\n",
    "\n",
    "![Screenshot of the buttons at the top of a Jupyter Notebook. The Run and Save buttons are highlighted](https://static-assets.codecademy.com/Paths/ds-python/jupyter-buttons.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae023367",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9378e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from pprint import pprint\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seed() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be577a32",
   "metadata": {},
   "source": [
    "To spare our Codecademy computers a little extra work, we've cut the IMDB dataset down to a smaller CSV file, which we'll import via pandas. If you'd like to see the Hugging Face card for the whole Dataset, check it out [here](https://huggingface.co/datasets/imdb).\n",
    "\n",
    "Execute the next four code cells to import the data and explore it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0fc407",
   "metadata": {},
   "source": [
    "### Imports and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81527792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label dataset\n",
      "0  There is no relation at all between Fortier an...      1   train\n",
      "1  This movie is a great. The plot is very true t...      1   train\n",
      "2  George P. Cosmatos' \"Rambo: First Blood Part I...      0   train\n",
      "3  In the process of trying to establish the audi...      1   train\n",
      "4  Yeh, I know -- you're quivering with excitemen...      0   train\n",
      "Number of null values:\n",
      "text       0\n",
      "label      0\n",
      "dataset    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('imdb_data.csv')\n",
    "print(df.head())\n",
    "print(\"Number of null values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3022245",
   "metadata": {},
   "source": [
    "As you can see, it's pretty simple: the `text` column holds the reviews themselves, while `label` is 1 or 0 (1 is positive sentiment, 0 is negative sentiment.) Finally, the `dataset` column separates the data into training and test sets. There are no null values in the dataset--thanks, Hugging Face!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e7904d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2500 entries, 0 to 2499\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   text     2500 non-null   object\n",
      " 1   label    2500 non-null   int64 \n",
      " 2   dataset  2500 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 58.7+ KB\n",
      "None\n",
      "\n",
      "\n",
      "Dataframe Description:\n",
      "             label\n",
      "count  2500.000000\n",
      "mean      0.495200\n",
      "std       0.500077\n",
      "min       0.000000\n",
      "25%       0.000000\n",
      "50%       0.000000\n",
      "75%       1.000000\n",
      "max       1.000000\n",
      "\n",
      "\n",
      "Number of unique values in each column:\n",
      "text       2499\n",
      "label         2\n",
      "dataset       2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataframe Info:\")\n",
    "print(df.info())\n",
    "print(\"\\n\")\n",
    "print(\"Dataframe Description:\")\n",
    "print(df.describe())\n",
    "print(\"\\n\")\n",
    "print(\"Number of unique values in each column:\")\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d692263e",
   "metadata": {},
   "source": [
    "We've got 2500 rows. Let's take a look at a random review to get a feel for how they sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b091284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A great, funny, sweet movie with Morgan Freeman (who plays himself) and who '\n",
      " 'meets a Spanish girl named Scarlet (Paz Vega) at a small store whilst '\n",
      " 'researching a potential independent film. I was a bit dubious about the film '\n",
      " 'for the first ten minutes but as soon as he was in the store I really '\n",
      " 'started to enjoy the film. It shows how a positive attitude can change '\n",
      " 'anything. It does not contain any complex plots and it is easy to follow but '\n",
      " 'will lift the saddest of moods and make you smile all the way through '\n",
      " 'without the need for petty cliché romance. It includes several scenes all '\n",
      " 'the way through which make you clutch your sides with laughter. A very rare '\n",
      " 'masterpiece!')\n"
     ]
    }
   ],
   "source": [
    "random_index = random.randint(0, len(df) - 1)\n",
    "pprint(df.loc[random_index, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e3a701d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tokenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<00:00, 216kB/s]\n",
      "Downloading config.json: 100%|██████████| 483/483 [00:00<00:00, 1.44MB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 99.8MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 56.5MB/s]\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (936 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest review length (in tokens): 35\n",
      "Longest review length (in tokens): 1470\n",
      "Average review length (in tokens): 300.0068\n"
     ]
    }
   ],
   "source": [
    "# Curious how this tokenization code works? We'll cover it in more detail at the end of this exercise.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\") # this tokenizer will work for our smaller model\n",
    "tokenized_reviews = df['text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "review_token_lengths = tokenized_reviews.apply(len)\n",
    "print(f\"Shortest review length (in tokens): {review_token_lengths.min()}\")\n",
    "print(f\"Longest review length (in tokens): {review_token_lengths.max()}\")\n",
    "print(f\"Average review length (in tokens): {review_token_lengths.mean()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39acbdc",
   "metadata": {},
   "source": [
    "Note the warning in the last cell's output above. Some of the examples in the dataset are longer than our model can intake. We'll need to be careful about how we handle the longer reviews in our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a945950",
   "metadata": {},
   "source": [
    "### Evaluating the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab94a658",
   "metadata": {},
   "source": [
    "#### Checkpoint 1/3\n",
    "\n",
    "Now that we've explored our data, let's evaluate the base model's performance with test data. This way, we'll have a basic idea of how much better our finetuned model is at classifying the sentiment of movie reviews relative to the model it was based on.\n",
    "\n",
    "Hugging Face's Dataset library has a helpful method, `from_pandas`, that can convert a DataFrame into a Hugging Face Dataset.\n",
    "\n",
    "Call the `from_pandas` method of `Dataset` below, passing in our DataFrame (`df`) as the argument.\n",
    "\n",
    "Don't forget to run the cell and save the notebook before selecting `Test Work`! Open the `Jupyter Help` toggle at the top of the notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b318baec",
   "metadata": {
    "deletable": false,
    "tags": [
     "cp1"
    ]
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "## YOUR SOLUTION HERE ##\n",
    "dataset= Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a172e5e",
   "metadata": {},
   "source": [
    "#### Checkpoint 2/3\n",
    "\n",
    "Next we'll tokenize the data.\n",
    "\n",
    "Hugging Face provides a useful `.map` method to instantiated datasets. Just pass it a function that takes in the data you want tokenized and outputs the tokenized data.\n",
    "\n",
    "We've defined the `tokenize_function` for you. At the bottom of the cell, use our `dataset`'s `.map()` method to tokenize the data. You'll do this by passing the `tokenize_function` as the first argument, and passing `batched=True` as the second argument so that we'll tokenize the text in batches.\n",
    "\n",
    "Don't forget to run the cell and save the notebook before selecting `Test Work`! Open the `Jupyter Help` toggle at the top of the notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e73ed471",
   "metadata": {
    "deletable": false,
    "tags": [
     "cp2"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2500/2500 [00:00<00:00, 2870.11 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"longest\", truncation=True)\n",
    "\n",
    "## YOUR SOLUTION HERE ##\n",
    "tokenized_dataset= dataset.map(tokenize_function, batched = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51f8289",
   "metadata": {},
   "source": [
    "Good. We'll now instantiate our model, a tiny version of BERT that will be great for learning the basics of writing finetuning code. Execute the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50740a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 285/285 [00:00<00:00, 1.78MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 17.8M/17.8M [00:00<00:00, 75.7MB/s]\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d481799",
   "metadata": {},
   "source": [
    "#### Checkpoint 3/3\n",
    "\n",
    "While our warning correctly reminds us that bert-tiny is not ready for production use and should instead first be finetuned, we're going to evaluate it anyway by passing it our test data.\n",
    "\n",
    "That way, we'll have a basic idea of whether or not our finetuning run actually improves the model's ability to classify movie reviews.\n",
    "\n",
    "If you see some unfamiliar code in the cell below, don't worry. We'll cover everything in greater detail soon. For now, tell the model it's in 'evaluation mode' (and not 'training mode') by passing the arguments `do_train=False` and `do_eval=True` to the `TrainingArguments()` call.\n",
    "\n",
    "Then, on the line where we define `eval_results`, run `trainer.evaluate()`. This will print `eval_results` to the console on the next line.\n",
    "\n",
    "Don't forget to run the cell and save the notebook before selecting `Test Work`! Open the `Jupyter Help` toggle at the top of the notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ddf801b",
   "metadata": {
    "deletable": false,
    "tags": [
     "cp3"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 2500/2500 [00:00<00:00, 2573.82 examples/s]\n",
      "Detected kernel version 4.14.355, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "[codecarbon INFO @ 05:16:24] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 05:16:24] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 05:16:24] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 05:16:24] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 05:16:24] No CPU tracking mode found. Falling back on CPU constant mode.\n",
      "[codecarbon INFO @ 05:16:26] CPU Model on constant consumption mode: Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz\n",
      "[codecarbon INFO @ 05:16:26] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 05:16:26]   Platform system: Linux-4.14.355-277.647.amzn2.x86_64-x86_64-with-glibc2.35\n",
      "[codecarbon INFO @ 05:16:26]   Python version: 3.10.12\n",
      "[codecarbon INFO @ 05:16:26]   CodeCarbon version: 2.3.1\n",
      "[codecarbon INFO @ 05:16:26]   Available RAM : 30.948 GB\n",
      "[codecarbon INFO @ 05:16:26]   CPU count: 8\n",
      "[codecarbon INFO @ 05:16:26]   CPU model: Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz\n",
      "[codecarbon INFO @ 05:16:26]   GPU count: 1\n",
      "[codecarbon INFO @ 05:16:26]   GPU model: 1 x Tesla T4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='157' max='157' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [157/157 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7226571440696716, 'eval_runtime': 1.5537, 'eval_samples_per_second': 804.506, 'eval_steps_per_second': 101.046}\n"
     ]
    }
   ],
   "source": [
    "# this is a Hugging Face method that makes it easy to filter our dataset for only 'test' data\n",
    "eval_dataset = tokenized_dataset.filter(lambda x: x['dataset'] == 'test')\n",
    "\n",
    "## YOUR SOLUTION HERE ##\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./temp_results',  \n",
    "    do_train= False,\n",
    "    do_eval= True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=eval_dataset\n",
    ")\n",
    "\n",
    "## YOUR SOLUTION HERE ##\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd731e6",
   "metadata": {},
   "source": [
    "Consider writing down the `eval_loss` number, as we'll be comparing it to the finetuned models later."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
