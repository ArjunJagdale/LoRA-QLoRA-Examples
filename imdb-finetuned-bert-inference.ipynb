{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8246b47c",
   "metadata": {},
   "source": [
    "<details><summary style=\"display:list-item; font-size:16px; color:blue;\">Jupyter Help</summary>\n",
    "    \n",
    "Having trouble testing your work? Double-check that you have followed the steps below to write, run, save, and test your code!\n",
    "    \n",
    "[Click here for a walkthrough GIF of the steps below](https://static-assets.codecademy.com/Courses/ds-python/jupyter-help.gif)\n",
    "\n",
    "Run all initial cells to import libraries and datasets. Then follow these steps for each question:\n",
    "    \n",
    "1. Add your solution to the cell with `## YOUR SOLUTION HERE ## `.\n",
    "2. Run the cell by selecting the `Run` button or the `Shift`+`Enter` keys.\n",
    "3. Save your work by selecting the `Save` button, the `command`+`s` keys (Mac), or `control`+`s` keys (Windows).\n",
    "4. Select the `Test Work` button at the bottom left to test your work.\n",
    "\n",
    "![Screenshot of the buttons at the top of a Jupyter Notebook. The Run and Save buttons are highlighted](https://static-assets.codecademy.com/Paths/ds-python/jupyter-buttons.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae023367",
   "metadata": {},
   "source": [
    "**Setup**\n",
    "\n",
    "Import our transformers modules to get started. We've uploaded the finetuned model from the last exercise for you, which is accessed below via `\"bathrobe/our_finetuned_model\"`, though if you were loading it in locally you'd pass `\"./finetunedmodel\"` (assuming the model folder is in the same folder as your notebook). Instantiate the model and tokenizer and we can get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9378e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading config.json: 100%|██████████| 691/691 [00:00<00:00, 2.45MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 17.5M/17.5M [00:00<00:00, 270MB/s]\n",
      "Downloading tokenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<00:00, 273kB/s]\n",
      "Downloading config.json: 100%|██████████| 570/570 [00:00<00:00, 2.80MB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 102MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 34.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "\n",
    "# if you were loading the model in locally (in the same folder as your notebook)\n",
    "# you'd pass \"./our_finetuned_model\" instead\n",
    "model_path = \"bathrobe/our_finetuned_model\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079e0e0c",
   "metadata": {},
   "source": [
    "#### Checkpoint 1/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c74d0",
   "metadata": {},
   "source": [
    "First, define a pipeline with a model and a tokenizer. Pass `'text-classification'` as the task to the pipeline, then `model=model` and `tokenizer=tokenizer`.\n",
    "\n",
    "Then, write a short movie review on the `single_text` line and assign `result` the classifier pipeline running on `single_text`.\n",
    "\n",
    "Don't forget to run the cell and save the notebook before selecting `Test Work`! Open the `Jupyter Help` toggle at the top of the notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b318baec",
   "metadata": {
    "deletable": false,
    "tags": [
     "cp1"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: LABEL_0, Score: 0.5609554648399353\n"
     ]
    }
   ],
   "source": [
    "## YOUR SOLUTION HERE ##\n",
    "classifier = pipeline('text-classification', model = model, tokenizer = tokenizer)\n",
    "single_text = \"Worst movie\"\n",
    "result = classifier(single_text)\n",
    "\n",
    "print(f\"Prediction: {result[0]['label']}, Score: {result[0]['score']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a172e5e",
   "metadata": {},
   "source": [
    "#### Checkpoint 2/3\n",
    "\n",
    "This same approach works for batches. Define a list of movie reviews in `batch_texts` and run them through the classifier, same as before.\n",
    "\n",
    "Don't forget to run the cell and save the notebook before selecting `Test Work`! Open the `Jupyter Help` toggle at the top of the notebook for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e73ed471",
   "metadata": {
    "deletable": false,
    "tags": [
     "cp2"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for text 1: LABEL_1, Score: 0.6212065815925598\n",
      "Prediction for text 2: LABEL_0, Score: 0.5609554648399353\n",
      "Prediction for text 3: LABEL_0, Score: 0.569589376449585\n"
     ]
    }
   ],
   "source": [
    "## YOUR SOLUTION HERE ##\n",
    "batch_texts = [\"Best movie\", \"worst movie\", \"The movie was somewhat good\"]\n",
    "results = classifier(batch_texts)\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Prediction for text {i+1}: {result['label']}, Score: {result['score']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
